\chapter{Conclusions and Future Work}
\label{chapter:conclusions}

%

The overall objective of this thesis is to improve the understanding and operational management of declarative KG construction languages, as stated in \cref{sec:chp3-objectives}. To that end, we focus on three specific objectives: (i) understanding and gathering the current needs for KG construction, supporting the evolution of mapping languages to address them; (ii) helping knowledge engineers and domain experts to build mapping documents, providing the means for a user-friendly experience; and (iii) assessing the value of declarative KG construction technologies for supporting KGs in their evolution. These objectives are fulfilled with the contributions presented in the thesis.

In this chapter we present a summary of the contributions, how they meet the objectives and the conclusions derived from them (\cref{sec:chp7_summary}), as well as the future lines of research (\cref{sec:chp7_future-work}). 

\section{Contributions Summary and Conclusions}
\label{sec:chp7_summary}
%% (i) understanding and gathering the current needs for KG construction, supporting the evolution of mapping languages to address them;
% Framwork, CM y RML-star
\begin{itemize}
    \item Regarding the first objective \textit{O1: To analyze the needs for declarative knowledge graph construction from heterogeneous data sources, in order to facilitate the support of advances in existing mapping languages to address the most relevant ones}, we first conducted an \textbf{extensive, fine-grained analysis of the expressiveness of the state of the art mapping specifications}, presented as a comparison framework. 
    We studied the characteristics of diverse mapping languages, a total of 16, based on different schemas (RDF and SPARQL mainly, among others), both pioneers and recent ones. 
    We evaluated their features regarding data source and access description, triple generation and additional features (such as data transformation functions, linking rules, conditions, named graphs, etc.). 
    This analysis shed light on the understanding of these languages. It establishes the basis of the thesis, allowing us to identify the shared characteristics and their ultimate goal, their differential capabilities and the motivation behind them, how the needs have evolved and the new language releases and extensions with them, as well as their limitations.
    
    From this analysis, \textbf{a set of requirements for KG construction was extracted and enriched with the concerns from the community}, published as mapping challenges. 
    These requirements were implemented in the Conceptual Mapping ontology gathering the expressiveness of the analysed languages and extending them with open challenges. This showcases how the requirements can be implemented in RDF-based languages, and it opens the door to language interoperability. 
    However, not all the features and capabilities of SPARQL-based languages could be implemented, as they can specify "instructions" for KG construction in a similar way that procedural languages do, and it is out of the scope for representing them in an ontology. 
    The ontology was evaluated by validating that the features provided in the language can address the set of requirements. 
    
    The evolution of the set of requirements in KGC led to the \textbf{development of RML-star, an extension for of RML for constructing RDF-star graphs}, which has become a module of the new RML release. 
    This module was developed along with a set of test cases, used to evaluate the conformance of an engine with respect to the language specification. 
    The proposal was validated with two use cases, with data from (i) biomedical research literature and (ii) scientific software metadata extraction. 
    The language could satisfy the needs of both use cases, thus reporting that it can successfully describe the generation of RDF-star graphs. 
    
    \textit{Conclusion.} Throughout the development of these contributions, we learned that, despite the wide variety of mapping languages, there is still a need to improve their capabilities. The declarative approach that they allow for constructing KGs brings a set of benefits, but they are still far from being as powerful as if the process was done with procedural languages (i.e., programming scripts) or SPARQL-based languages. Additionally, the semantic technologies are not static, they keep on evolving, and along with them, the requirements for KG construction. Hence, there is a continuous need to keep up-to-date  with them. In the past few years, a community came together to tackle this issue, with the objective of identifying and overcoming current limitations in the languages to produce a versatile resource that can address more complex use cases, and that can be useful for a broader audience. %\ana{las ideas están desorganizadas, pero importancia en la comunidad, ideas y visiones distintas para llegar a una abstracción lo mas versátil posible, sin caer en islas como estaban anteriormente los lenguajes. }
\end{itemize}


%Lo primero de todo, diseñamos y ejecutamos un comparison framework. Esto trajo beneficios sentando las bases de la tesis: analizamos las posibilidades y features de mucha variedad de lenguajes, basados en distintos esquemas y diseñados para distintos casos de uso, tanto recientes como más antiguos. Esto dio mucha perspectiva, ya que permite entender  las partes comunes y su fin último, las diferencias y motivaciones que llevaron a su desarrollo, y cómo han ido evolucionando con las necesidades cada vez más exigentes para llegar a más casos de uso. 
%Tanto de aquí como de ver las inquietudes de la comunidad al final se llegaron a una serie de requisitos. Estos requisitos se implementaron como una ontología, recogiendo la expresividad de distintos lenguajes y extendiendola con los challenges que se habían encontrado, abriendo la puerta a una posible interoperabilidad entre ellos. 
%El encontrar nuevos retos y features aun no cubiertas en actuales lenguajes utilizados motivó la colaboración con el CG para implementar en RML la extensión para generar RDF-star graphs, RML-star. 
%De esta forma, seguimos trabajando en estas tecnologías para poder cubrir cada vez más casos de usos reales, estando actualizados con las necesidades actuales según las semweb technologies avanzan alrededor
%como reflexión, importancia de comunidad, distintas perspectivas y casos de uso para hacer los recursos lo más generales y útiles posibles, y para el soporte para no quedarnos atrás y seguir siendo competitivos con los otros approaches no declarativos para crear grafos



\begin{itemize}
    \item For the second objective \textit{O2: To help knowledge engineers and domain experts build declarative mappings in a user-friendly manner}, we focus on improving the mapping writing process with two different approaches. 
    The first one involved the \textbf{development of a familiar spreadsheet-environment for writing the mapping transformation rules}. 
    This approach aimed at facilitating the task for any user, but in particular profiles with no technical background that may struggle with the language's or serialization's syntax. 
    The spreadsheet design proposed is an abstract representation of the transformation rules, what enables their translation into different languages. 
    This approach was implemented in the tool Mapeathor, able to process Excel and Google Spreadsheets and generate mapping documents in R2RML, RML and YARRRML. 
    The spreadsheet design was evaluated in a user study with the baseline, RML and a visual editor, RMLEditor. 
    The pool of participants included 30 practitioners with heterogeneous backgrounds and expertise.
    The evaluation required participants to write some mapping rules in a fixed amount of time given the needed inputs. 
    The results revealed that the proposed spreadsheet-based environment favoured the writing in terms of accuracy and completeness compared to the other two.
    This motivates us to keep improving the spreadsheet design and implementation, to address the limitations raised by the participants and keep up to date with the currently evolving languages. 
    
    The second approach involved \textbf{extending the YARRRML serialization for RML, YARRRML-star}. 
    This extensions included some of the latest advances in the new RML specification, RML-star among them. 
    We also developed along with the serialization extensions a set of test cases, and the approach was validated in terms of expressiveness with other user friendly syntax (ShExML, SMS2 and XRM). 
    A compliant implementation, Yatter, was developed along to translate bidirectionally YARRRML-star, RML and R2RML. 
    This implementation successfully passed the proposed test cases, and serves towards the interoperability of these languages.
    
    \textit{Conclusion.} One of the biggest challenges for spreading the adoption of the use of mapping languages for KG construction is their steep learning curve. The diversity of languages, an advantage for heterogeneity and expressiveness, supposes a setback in this regard, along with the general lack of interoperability. Despite the amount of visual editors developed after the R2RML recommendation, none of these tools was really widely adopted. User-friendly serializations have been more successful, but they still impose a barrier for non-technical profiles. These contributions aim at lowering the learning barrier and facilitate the writing for different profiles, so that mapping languages can be more easily adopted and used. 
\end{itemize}


%% (ii) helping knowledge engineers and domain experts to build mapping documents, providing the means for a user-friendly experience
% Spreadsheets, Mapeathor; YARRRML-star y Yatter
%El mayor problema que tienen los mappings es que a la gente le cuesta aprender, aparte la enorme heterogeneidad y falta de interoperabilidad entre ellos no ayuda. Los approaches visuales no han terminado de funcionar y a pesar de la cantidad de editores que se desarrollaron en la pasada de´cada especialmente para R2RML, no han terminado de cuajar. Las serializaciones sí han tenido más éxito, pero restringen el usuario final, ya que sigue siendo necesario pegarse con una sintaxis que no tiene que ser familiar. 
%Por este motivo se diseñó un approach en un entorno familiar para -todo el mundo-, las spreadsheets, para escribir ahí las reglas de transformación. Este approach permite la creación de reglas en diversos lenguajes, y se evaluó con usuarios con distinto background y expertise para ver si puede llegar a todo el mundo, como es el objetivo. Los resultados son sorprendentemente buenos, y motivan el desarrollo en este sentido, aunque también evidencian las limitaicones actuales y cómo se puede mejorar la experiencia del usuario para que sea más amena la escritura. 
%Como el objetivo es la adopción, y lo que por ahora se ha adoptado mejor es RML y YARRRML, se ha trabajado en colaboraicón para extender la serialización actual con las nuevas actualizaciones en el lenguaje RML. 
%De esta forma queremos facilitar de diversas formas que estas tecnologías tengan más alcance y sean más accesibles a usuarios de distintos perfiles, para facilitar la transición a los approaches declarativos y estandarizados, evitando los desarrollos ad-hoc.

%reflexión: no ha habido suficiente reflexión en qué ha ido mal para que los lenguajes sean tan costosos de aprender, hasta para expertos en semweb, y claramente no se han tenido muy en cuenta las preferencias del usuario cuando de todos los editores no hay ninguno qeue haya tenido éxito. Para que tenga sentido el seguir avanzando con los lenguajes no podemos olvidarnos de facilitar al usuario su uso, 


% historia/motivación de cómo se ha llegado a esa contribución
% qué se ha hecho
% cómo se ha validado/evaluado
% qué se ha conseguido con ello

%% (iii) assessing the value of declarative mapping technologies for supporting KGs in their evolution
% construct or re-construct, support in evolution not only in construction

\begin{itemize}
    \item For the third objective \textit{O3: To assess declarative knowledge graph construction technologies in terms of their benefits for supporting the creation and evolution of knowledge graphs}, we \textbf{evaluated the support of declarative KG construction technologies in the evolution of the schema of a knowledge graph}. We considered the changes in schema that comes with change in the reification of triples, motivated from different real use cases. These reification approaches model the same knowledge with different strategies, which affect the performance of downstream tasks. We evaluated the re-construction of a knowledge graph (i) from the original data sources with mapping technologies and (ii) pairwise from each representation with \texttt{CONSTRUCT} queries within a triplestore. The experiment was executed using different mapping languages along with their corresponding engines (RML with Morph-KGC and Facade-X with SPARQL-Anything) and triplestores (GraphDB, Jena Fuseki and Oxigraph). The results showed that for small amounts of data, triplestores were faster, but mapping technologies appeared as a more scalable approach as the data size increases, and robust to the changes of different representations. The re-construction process is also facilitated since how the \texttt{CONSTRUCT} queries are written highly influences the performance of triplestores, while it is indifferent in mapping documents. 

    \textit{Conclusion.} Mapping languages were developed for constructing KGs. The effort put  to improve these declarative technologies has produced a set of mature resources optimized for construction, but also able to tackle more tasks within the knowledge graph life cycle (e.g., data pre-processing with transformation functions, metadata annotation). The contribution of this thesis in this regard is to demonstrate also its potential for the long-term maintenance supporting the schema evolution of KGs. It shows the maturity level of declarative mapping-compliant technologies with respect to well established resources as triplestores, and how it can also bring benefits to users to perform the change of schema. 
\end{itemize}

%Recapitulando de lo anterior, en cada parte hay un problema distinto que lleva como consecuencia la dificultad en adopción. Uno con limitaciones para construction, otro barrera de aprendizaje. Aunque esto cada vez va mejorando, muchas veces falta motivación en cómo puede mejroar todo esto el ciclo de vida de un KG. Se ha trabajado duramente para optimizar el proceso de construcción, describir data transformation rules, el output... Dejando la ejecución en manos de herramientas optimizadas para ello (ya que también se ha trabajdo en estas optimizaciones). Aunque el foco está en la construcción, también puede ayudar en la re-construcción; en KGs ya creados que tengan que cambiar su estructura. Para grandes volumenes de datos estos approaches se ha visto que son mejores que con tripelstores, y llevan menos problemas a la hora de hacer el cambio de estructura: las optimizaciones en las queries son un problema y solo expertos las saben; mientras que con mappings pues no pasa eso. 



\section{Future Work}
\label{sec:chp7_future-work}

%% FUTURE WORK

Following, we present some open challenges and issues that have not been addressed in the thesis, or that have appeared during or as a consequence of the advances proposed in it. 

%\textcolor{shamrockgreen}{* de representaciones y consumption. toda la tesis se centra en la parte de construcción, pero es solo una parte más del ciclo de vida de los KGs. Aprender de cómo se usan, cambiar representación según cuál sea más eficienta para cada tarea concreta}

%\textcolor{shamrockgreen}{* can languages rdf-based be ever as expressive as sparql-based? or ad-hoc code?}

%\textcolor{shamrockgreen}{* keep up to date the user-friendly approaches with the new RML release, for now the implementation of the new modules is limited bc the change at the time of writing. look more into the preferences of users! kinda forgotten lately}

%\textcolor{shamrockgreen}{* to increase interoperability and backwards compatibility, implement translations between new and old spec. The new spec may not address all limitations identified, but it is expressive enough to deal with more use cases and it'd be easier to serve as reference translation point for the other currently used languages}

%\textcolor{shamrockgreen}{* estudiados cambios en reificaciones, pero no todos los cambios posibles que puedan afectar más tb en cómo se escriben los mappings o qué contengan}

%\textcolor{shamrockgreen}{* mirar cómo pueden mejorar los declarative approaches la transparencia del KG en ciclo de vida, para todo el proceso (paper ME y mirar el de review de K-CAP)}

%\textcolor{shamrockgreen}{* governance for mappings?}

%\textcolor{shamrockgreen}{* LLMs for facilitating the process}

To be able to progress in declarative KGC technologies, there are three essential factors involved: (i) knowing which are the technical necessities for constructing KGs, (ii) acknowledging the needs of the target audience that is going to use them and (iii) developing technologies and resources able to meet the needs gathered in (i) and (ii). 
Despite the recent efforts in gathering the technical necessities, this is an on-going line of work that will continue in the future. While the semantic technologies advance and evolve, there will always be the need to keep up to date to produce KGs able to serve the tasks they are created for. The needs and preferences of users, specially with non-technical profiles, need to be put in the center. We need to learn from previous success and failure stories to put the efforts into developments easier to adopt and keep expanding the community of users into a broader audience. %\textit{Getting closer or learning from the HCI disciplines, integrate current developments with widely used implementations (wikimedia stuff)} 

Regarding mapping languages and their capability to fully address current KG construction needs, we think there is still room for improvement in terms of expressiveness. Specially RDF-based languages have limitations in how they can represent the transformation, a limitation that for SPARQL-based languages is softer. Currently, there have been progresses in this regard with the collaboration with the Knowledge Graph Construction W3C Community Group in addressing some of the identify challenges. We believe that keeping up the collaboration with a heterogeneous community with different backgrounds, perspectives and use cases in collaboration will lead to a resource available and useful for an increasingly wider audience.

There is also plenty of work to boost adoption of declarative approaches for KG construction. A key aspect of this issue is demonstrating the overall benefits compared to ad-hoc approaches. In this regard, this thesis is focused on the evolution step of the KG life cycle in a restricted scenario: change of schema from different metadata representation approaches. There are studies showing the differential performance of KGC engines based on the characteristics of the mappings. We need to study these changes further, considering also changes in the data and not only the KG schema, to assess their role in a wider set of evolution scenarios. We are also keen in assessing further their role for empowering the transparency of workflows supporting the KG life cycle.

Lastly, the recent success of Large Language Models (LLM) opens the door to multiple possibilities. These models can be suitable for enhancing different tasks during the KG life cycle, from the development of ontologies, to the KG construction and usage. In particular, they have proven successful for user interaction, which can in particular help in KG consumption and enrolment of users in the KG development process.



 %% frase más general que enmarque las tres partes?
%remark value
%expand expressiveness to address new needs and existing limitations
%improve user experience to increase adoption 
